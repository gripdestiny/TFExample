{
 "metadata": {
  "name": "",
  "signature": "sha256:eadbf7c8592273333cff3d6bf52937def43218865514aec695512a58983a88a9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import os\n",
      "import pickle\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u6458\u81eaCS231n\u8bfe\u7a0b\u4f5c\u4e1a\uff0c\u53c2\u8003cifar10\u5b98\u7f51\u505a\u51fa\u5c0f\u4fee\u6539\n",
      "def load_CIFAR_batch(filename):\n",
      "  \"\"\" load single batch of cifar \"\"\"\n",
      "  with open(filename, 'rb') as f:\n",
      "    datadict = pickle.load(f, encoding='bytes')#\u6dfb\u52a0encoding='bytes'\n",
      "    #print(datadict.keys())\n",
      "    X = datadict[b'data']#\u6dfb\u52a0b\n",
      "    Y = datadict[b'labels']#\u6dfb\u52a0b\n",
      "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
      "    Y = np.array(Y)\n",
      "    return X, Y\n",
      "\n",
      "def load_CIFAR10(ROOT):\n",
      "  \"\"\" load all of cifar \"\"\"\n",
      "  xs = []\n",
      "  ys = []\n",
      "  for b in range(1,6):\n",
      "    f = os.path.join(ROOT, 'data_batch_{}'.format(str(b)))\n",
      "    #print(f)\n",
      "    X, Y = load_CIFAR_batch(f)\n",
      "    xs.append(X)\n",
      "    ys.append(Y)    \n",
      "  Xtr = np.concatenate(xs)\n",
      "  Ytr = np.concatenate(ys)\n",
      "  del X, Y\n",
      "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
      "  return Xtr, Ytr, Xte, Yte"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cifar10_dir = 'datasets/cifar-10-batches-py'\n",
      "X_train,y_train,X_test,y_test = load_CIFAR10(cifar10_dir)\n",
      "print(X_train.shape)\n",
      "print(y_train.shape)\n",
      "print(X_test.shape)\n",
      "print(y_test.shape)\n",
      "X_train /= 255.\n",
      "X_test /= 255."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 32, 32, 3)\n",
        "(50000,)\n",
        "(10000, 32, 32, 3)\n",
        "(10000,)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u5c06label\u8f6c\u6210one-hot vector\n",
      "def one_hot(input_labes):\n",
      "    out_labels=[]\n",
      "    for i in range(len(input_labes)):\n",
      "        label = 10*[0]\n",
      "        label[input_labes[i]]=1\n",
      "        out_labels.append(label)\n",
      "    return np.array(out_labels)\n",
      "y_train_onehot = one_hot(y_train)\n",
      "y_test_onehot = one_hot(y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def conv2d(X_input,kernel,strides,pad):\n",
      "      \n",
      "    W = tf.Variable(tf.truncated_normal(shape=kernel,stddev=0.1))\n",
      "    b = tf.Variable(tf.constant(0.1,shape=[kernel[-1]]))\n",
      "    return tf.nn.relu(tf.nn.conv2d(X_input,W,strides=strides,padding=pad)+b)\n",
      "\n",
      "\n",
      "def max_pool(X_input,ksize,strides,pad):\n",
      "    return tf.nn.max_pool(X_input,ksize=ksize,strides=strides,padding=pad)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_width = 32\n",
      "image_height = 32\n",
      "channel = 3\n",
      "num_labels = 10\n",
      "batchsize = 50\n",
      "max_iter = 250000\n",
      "X_input = tf.placeholder(tf.float32,shape=[None,image_width,image_height,channel])\n",
      "y_label = tf.placeholder(tf.float32,shape=[None,num_labels])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#\u5377\u79ef\u5c42\n",
      "conv_strides = [1,1,1,1]\n",
      "conv_pad = 'SAME'\n",
      "pool_ksize = [1,2,2,1]\n",
      "pool_strides = [1,2,2,1]\n",
      "pool_pad = 'SAME'\n",
      "\n",
      "\n",
      "layer1 = conv2d(X_input,[3,3,3,64],conv_strides,conv_pad)\n",
      "layer2 = conv2d(layer1,[3,3,64,64],conv_strides,conv_pad)\n",
      "pool1 = max_pool(layer2,pool_ksize,pool_strides,pool_pad)\n",
      "\n",
      "layer3 = conv2d(pool1,[3,3,64,128],conv_strides,conv_pad)\n",
      "layer4 = conv2d(layer3,[3,3,128,128],conv_strides,conv_pad)\n",
      "pool2 = max_pool(layer4,pool_ksize,pool_strides,pool_pad)\n",
      "\n",
      "layer5 = conv2d(pool2,[3,3,128,256],conv_strides,conv_pad)\n",
      "layer6 = conv2d(layer5,[3,3,256,256],conv_strides,conv_pad)\n",
      "layer7 = conv2d(layer6,[3,3,256,256],conv_strides,conv_pad)\n",
      "layer8 = conv2d(layer7,[3,3,256,256],conv_strides,conv_pad)\n",
      "pool3 = max_pool(layer8,pool_ksize,pool_strides,pool_pad)\n",
      "\n",
      "layer9 = conv2d(pool3,[3,3,256,512],conv_strides,conv_pad)\n",
      "layer10 = conv2d(layer9,[3,3,512,512],conv_strides,conv_pad)\n",
      "layer11 = conv2d(layer10,[3,3,512,512],conv_strides,conv_pad)\n",
      "layer12 = conv2d(layer11,[3,3,512,512],conv_strides,conv_pad)\n",
      "pool4 = max_pool(layer12,pool_ksize,pool_strides,pool_pad)\n",
      "\n",
      "layer13 = conv2d(pool4,[3,3,512,512],conv_strides,conv_pad)\n",
      "layer14 = conv2d(layer13,[3,3,512,512],conv_strides,conv_pad)\n",
      "layer15 = conv2d(layer14,[3,3,512,512],conv_strides,conv_pad)\n",
      "layer16 = conv2d(layer15,[3,3,512,512],conv_strides,conv_pad)\n",
      "pool5 = max_pool(layer16,pool_ksize,pool_strides,pool_pad)\n",
      "\n",
      "pool5_shape = pool5.get_shape().as_list()\n",
      "nodes = pool5_shape[1] * pool5_shape[2] * pool5_shape[3]\n",
      "pool5 = tf.reshape(pool5,[-1,nodes])\n",
      "print(nodes)\n",
      "'''\n",
      "layer1 = conv2d(X_input,[3,3,3,6],conv_strides,conv_pad)\n",
      "pool1 = max_pool(layer1,pool_ksize,pool_strides,pool_pad)\n",
      "\n",
      "layer2 = conv2d(layer1,[3,3,6,16],conv_strides,conv_pad)\n",
      "pool2 = max_pool(layer2,pool_ksize,pool_strides,pool_pad)\n",
      "\n",
      "pool4_shape = pool2.get_shape().as_list()\n",
      "nodes = pool4_shape[1] * pool4_shape[2] * pool4_shape[3]\n",
      "pool4 = tf.reshape(pool2,[-1,nodes])\n",
      "'''\n",
      "nodes_fc1 = 128\n",
      "nodes_fc2 = 64\n",
      "nodes_fc3 = 10\n",
      "\n",
      "W_fc1 = tf.Variable(tf.truncated_normal(shape=[nodes,nodes_fc1],stddev=0.1))\n",
      "b_fc1 = tf.Variable(tf.constant(0.1,shape=[nodes_fc1]))\n",
      "fc1 = tf.nn.relu(tf.matmul(pool5,W_fc1) + b_fc1)\n",
      "\n",
      "W_fc2 = tf.Variable(tf.truncated_normal(shape=[nodes_fc1,nodes_fc2],stddev=0.1))\n",
      "b_fc2 = tf.Variable(tf.constant(0.1,shape=[nodes_fc2]))\n",
      "fc2 = tf.nn.relu(tf.matmul(fc1,W_fc2) + b_fc2)\n",
      "\n",
      "W_fc3 = tf.Variable(tf.truncated_normal(shape=[nodes_fc2,nodes_fc3],stddev=0.1))\n",
      "b_fc3 = tf.Variable(tf.constant(0.1,shape=[nodes_fc3]))\n",
      "fc3 = tf.nn.relu(tf.matmul(fc2,W_fc3) + b_fc3)\n",
      "\n",
      "y_output = tf.nn.softmax(fc3)\n",
      "\n",
      "\n",
      "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_label,logits=y_output))\n",
      "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
      "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_label,1),tf.argmax(y_output,1)),tf.float32))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "512\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "init = tf.global_variables_initializer()\n",
      "idx = []\n",
      "train_loss = []\n",
      "train_accuracy = []\n",
      "with tf.Session() as sess:\n",
      "    sess.run(init)\n",
      "    for i in range(max_iter):\n",
      "        mask = np.random.choice(X_train.shape[0],batchsize,replace=False)\n",
      "        batch_x = X_train[mask]\n",
      "        batch_y = y_train_onehot[mask]\n",
      "        feed_dict = {X_input:batch_x,y_label:batch_y}\n",
      "        [_,temp_loss,temp_accuracy] = sess.run([train_step,loss,accuracy],feed_dict = feed_dict)\n",
      "        if i % 1000 == 0:\n",
      "            idx.append(i)\n",
      "            train_loss.append(temp_loss)\n",
      "            train_accuracy.append(temp_accuracy)\n",
      "            print('Step at #{}:'.format(i),end=' ' )\n",
      "            print('training loss is: {:.5f}'.format(temp_loss),end=' ')\n",
      "            print('training accuracy is: {:.2f}'.format(temp_accuracy*100))\n",
      "    print('test accuracy is: {:.2f}'.format(sess.run(accuracy,feed_dict={X_input:X_test,y_label:y_test})))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step at #0: training loss is: 2.42115 training accuracy is: 4.00\n",
        "Step at #1000:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " training loss is: 2.42115 training accuracy is: 4.00\n",
        "Step at #2000:"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax1 = plt.subplots()\n",
      "ax2 = ax1.twinx()\n",
      "ax1.plot(idx,train_loss,'r-')\n",
      "ax2.plot(idx,train_accuracy)\n",
      "ax1.set_xlabel('Iteration')\n",
      "ax1.set_ylabel('loss')\n",
      "ax2.set_ylabel('accuracy')\n",
      "plt.title('train cifar10 with vgg19-like')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}